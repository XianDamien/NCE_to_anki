# 2_process_with_ai.py
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import json
import os
import time
from dotenv import load_dotenv
import concurrent.futures

# --- é…ç½® ---
load_dotenv() 
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

MAX_PROCESS_WORKERS = 5 
MAX_THREAD_WORKERS_FOR_DRAFTS = 10
MAX_RETRIES_PER_SENTENCE = 3

BOOK_TO_PROCESS = 2
RAW_DATA_DIR = os.path.join("raw_data", f"nce_book_{BOOK_TO_PROCESS}")
PROCESSED_DATA_DIR = os.path.join("processed_data", f"nce_book_{BOOK_TO_PROCESS}")

GENERATION_CONFIG = {"temperature": 0.4, "top_p": 1, "top_k": 1, "max_output_tokens": 8192}
FLASH_MODEL_NAME = "gemini-2.5-flash"
PRO_MODEL_NAME = "gemini-2.5-pro"

# ------------
safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}

# <<< æ–°å¢ï¼šä¸ºç¬¬ä¸€é˜¶æ®µï¼ˆç”Ÿæˆè‰ç¨¿ï¼‰è®¾è®¡çš„Prompt >>>
prompt_for_draft = (
    "ä½ æ˜¯ä¸€ä½é¡¶çº§çš„è‹±è¯­è€å¸ˆï¼Œä¸“é—¨ä¸ºä¸­æ–‡ä¸ºæ¯è¯­ã€è¯æ±‡é‡åœ¨1000-2000çš„åˆå­¦è€…è®²è§£æ–°æ¦‚å¿µè‹±è¯­ã€‚ä½ çš„è®²è§£å¿…é¡»ç®€æ˜æ‰¼è¦ã€å½¢è±¡ç”ŸåŠ¨ã€å…¨éƒ¨ä½¿ç”¨ä¸­æ–‡ã€‚\n\n"
    "è¾“å‡ºæ ¼å¼è§„åˆ™ï¼š\n"
    "1. åˆ—è¡¨è¯·ç›´æ¥ä½¿ç”¨ â€œ1.â€, â€œ2.â€ è¿™æ ·çš„æ•°å­—å‰ç¼€ã€‚\n\n"
    "1. ç»å¯¹ä¸è¦ä½¿ç”¨ä»»ä½•Markdownæˆ–HTMLæ ‡ç­¾ï¼ˆä¾‹å¦‚ `<b>`, `<br>` ç­‰ï¼‰ã€‚æ‰€æœ‰å†…å®¹éƒ½å¿…é¡»æ˜¯çº¯æ–‡æœ¬ã€‚\n"
    "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ä¸‰éƒ¨åˆ†å†…å®¹å’Œæ ¼å¼ï¼Œä¸ºæä¾›çš„å¥å­ç”Ÿæˆå­¦ä¹ ç¬”è®°ï¼š\n"
    "è¦ç”¨åˆ°çš„è®²è§£æ¶æ„ï¼š å¥å‹-è¯æ€§ï¼šæ‰€æœ‰çš„ç®€å•å¥åªæœ‰äº”ç§ï¼ˆå³è‹±è¯­çš„äº”ç§å¥å‹ï¼‰â€”â€”ç”±å¥å­ä¸­çš„åŠ¨è¯å†³å®š/ç”±éœ€è¦è¡¨è¾¾çš„æ„æ€å†³å®šã€‚åŠ¨è¯ï¼šè¡¨ç¤ºçŠ¶æ€æˆ–åŠ¨ä½œçš„è¯æ±‡ï¼› ä¸åŠç‰©åŠ¨è¯vi.ï¼ŒåŠç‰©åŠ¨è¯vt.ï¼Œç³»åŠ¨è¯ï¼ˆis, seem, proveï¼Œè¡¨ç¤ºçŠ¶æ€ï¼‰ï¼ŒåŒå®¾è¯­åŠ¨è¯ï¼Œéœ€è¦å®¾è¡¥çš„åŠ¨è¯ç­‰ã€‚S + V (ä¸»è°“)**: The sun rises.S + V + O (ä¸»è°“å®¾)**: I love English.S + V + P (ä¸»è°“è¡¨)**: The story **is** true. (ç³»åŠ¨è¯)S + V + o + O (ä¸»è°“åŒå®¾)**: My mom bought **me** a **book**.S + V + O + C (ä¸»è°“å®¾è¡¥)**: I painted the wall **blue**."
    "1. è¯æ±‡ä¸çŸ­è¯­\n"
    "è§£é‡Šé‡ç‚¹å•è¯æˆ–è¯ç»„çš„å«ä¹‰ã€è¯æ€§(vt./vi./adj./adv.ç­‰)ã€å‘éŸ³éš¾ç‚¹å’Œå®ç”¨æ­é…ã€‚æ³¨æ„ï¼Œ2-5ä¸ªé‡ç‚¹å³å¯ï¼Œå¦åˆ™ä¼šç»™å­¦ä¹ è€…å¸¦æ¥ä¸å¿…è¦çš„æ–‡å­—å’Œè´Ÿæ‹…\n\n"
    "2. å¥å­ç»“æ„åˆ†æ\n"
    "è¿™æ˜¯æœ€é‡è¦çš„éƒ¨åˆ†ï¼ŒæŠŠæ‰€æœ‰çš„ç®€å•å¥éƒ½åˆ†æä¸€ä¸‹ï¼Œè¿‡äºç®€å•çš„å¥å­å¯ä»¥çœç•¥ã€‚è¯·ä¸¥æ ¼å‚è€ƒä»¥ä¸‹ç¤ºä¾‹çš„æ€è·¯å’Œæ ¼å¼è¿›è¡Œåˆ†æï¼š\n"
    "--- ç¤ºä¾‹å¼€å§‹ ---\n"
    "å¥å­: If you park your car in the wrong place, a traffic policeman will soon find it.\n"
    "åˆ†æ:\n"
    "è¿™æ˜¯ä¸€ä¸ªæ¡ä»¶å¥ï¼Œå‘Šè¯‰æˆ‘ä»¬ä¸€ä¸ªåŠ¨ä½œï¼ˆåœè½¦ï¼‰ä¼šå¸¦æ¥ä¸€ä¸ªåæœï¼ˆè¢«å‘ç°ï¼‰ã€‚\n"
    "1. è¿™ä¸ªå¥å­çš„â€œä¸»è§’â€æ˜¯ååŠéƒ¨åˆ† \"a traffic policeman will soon find it\" (è­¦å¯Ÿä¼šå‘ç°å®ƒ)ï¼Œè¿™æ˜¯ä¸€ä¸ªâ€œä¸»è°“å®¾â€å¥å‹ï¼Œæ¸…æ¥šåœ°è¯´æ˜äº†è­¦å¯Ÿä¼šåšä»€ä¹ˆäº‹ã€‚\n"
    "2. å‰åŠéƒ¨åˆ† \"If you park your car...\" (å¦‚æœä½ æŠŠè½¦åœåœ¨é”™è¯¯çš„åœ°æ–¹) æ˜¯ä¸€ä¸ªæ¡ä»¶ï¼Œåƒä¸ªâ€œå¦‚æœ...å°±...â€çš„å¼€å…³ï¼Œå‘Šè¯‰æˆ‘ä»¬â€œä¸»è§’â€äº‹ä»¶åœ¨ä»€ä¹ˆæƒ…å†µä¸‹ä¼šå‘ç”Ÿã€‚\n"
    "3. æ—¶æ€ï¼šä¸»å¥ç”¨äº†å°†æ¥æ—¶ (will find)ï¼Œè¡¨ç¤ºå¯¹æœªæ¥çš„é¢„æµ‹ï¼›æ¡ä»¶éƒ¨åˆ†ç”¨äº†ç°åœ¨æ—¶ (park) ä»£æ›¿å°†æ¥æ—¶ï¼Œè¿™æ˜¯ifæ¡ä»¶å¥çš„å›ºå®šè§„åˆ™ã€‚\n"
    "--- ç¤ºä¾‹ç»“æŸ ---\n"
    "3. ä¸¾ä¸€åä¸‰\n"
    "è¯·æä¾›1-2ä¸ªä¸åŸå¥æ ¸å¿ƒè¯æ±‡æˆ–å¥å‹ç›¸ä¼¼çš„ã€ç®€å•çš„ä¾‹å¥ï¼Œå¹¶é™„ä¸Šä¸­æ–‡ç¿»è¯‘ã€‚\n"
    "------------------------------------------------------------------\n\n"
    "æœ¬è¯¾ç”Ÿè¯å‚è€ƒ: {vocabulary}\n"
    "éœ€è¦åˆ†æçš„å¥å­:\n"
    "- è‹±æ–‡: \"{eng}\"\n"
    "- ä¸­æ–‡: \"{chn}\"\n\n"
)

# <<< æ–°å¢ï¼šä¸ºç¬¬äºŒé˜¶æ®µï¼ˆç²¾ç‚¼ç¬”è®°ï¼‰è®¾è®¡çš„Prompt >>>
prompt_for_refinement = (
    "ä½ æ˜¯ä¸€ä½é¡¶çº§çš„è‹±è¯­æ•™å­¦ç¼–è¾‘ï¼Œä½ çš„ä»»åŠ¡æ˜¯â€œç²¾ç‚¼å¹¶å…³è”â€ä¸€ä»½ç¬”è®°è‰ç¨¿ã€‚\n\n"
    "æ ¸å¿ƒåŸåˆ™ï¼š\n"
    "1. **ç²¾ç‚¼ç®€æ´**: ä¸¥æ ¼éµå®ˆâ€œå°‘å³æ˜¯å¤šâ€ï¼Œåˆ é™¤è‰ç¨¿ä¸­æ‰€æœ‰éå¿…è¦çš„ã€é‡å¤çš„æˆ–è¿‡äºåŸºç¡€çš„ä¿¡æ¯ã€‚æœ€ç»ˆç¬”è®°è¦ç®€æ˜æ‰¼è¦ï¼Œä¸è¦ç»™åˆå­¦è€…é€ æˆè´Ÿæ‹…ã€‚\n"
    "2. **æ·±åº¦å…³è”**: è¿™æ˜¯ä½ çš„æ ¸å¿ƒä»·å€¼ã€‚è¯·ä»”ç»†é˜…è¯»ä¸‹é¢æä¾›çš„â€œæœ¬è¯¾æ‰€æœ‰å…¶ä»–å¥å­çš„ç¬”è®°è‰ç¨¿â€ï¼Œå¦‚æœå½“å‰å¥å­çš„çŸ¥è¯†ç‚¹ï¼ˆè¯æ±‡/å¥å‹ï¼‰ä¸å®ƒä»¬æœ‰å…³è”ï¼Œè¯·ç”¨â€œè¿™å’Œæˆ‘ä»¬ä¹‹å‰é‡åˆ°çš„...ç±»ä¼¼â€æˆ–â€œæ³¨æ„åŒºåˆ†...â€ç­‰æ–¹å¼ç‚¹æ˜ï¼Œå¸®åŠ©å­¦ç”Ÿå»ºç«‹è”ç³»ã€‚\n"
    "3. **ä¼˜åŒ–è¡¨è¾¾**: ç”¨æ›´ç”ŸåŠ¨ã€æ›´æ˜“äºç†è§£çš„æ–¹å¼é‡å†™è‰ç¨¿ï¼Œç¡®ä¿æœ€ç»ˆç‰ˆæœ¬æ¸…æ™°ã€æµç•…ã€‚\n\n"
    "è¾“å‡ºæ ¼å¼ï¼šçº¯æ–‡æœ¬ï¼Œç”¨æ•°å­—å‰ç¼€åˆ†ç‚¹ã€‚ç»å¯¹ä¸è¦ä½¿ç”¨markdownæ ¼å¼ï¼ï¼ï¼ï¼ï¼ä¹Ÿä¸è¦ä½¿ç”¨\nçš„æ ¼å¼ï¼ï¼ï¼ï¼ï¼æ³¨æ„ç²¾ç‚¼ä¹‹åæ¯ä¸€ä¸ªå¥å­å¡ç‰‡çš„è§£æçš„å­—æ•°ä¸èƒ½è¶…è¿‡100å­—ï¼ï¼ï¼ï¼å…³è”å¼€å§‹çš„æ—¶å€™åªéœ€è¦æ ‡æ³¨ã€å…³è”ç‚¹ã€‘å³å¯\n"
    "------------------------------------------------------------------\n"
    "å½“å‰è¦ç²¾ç‚¼çš„å¥å­:\n"
    "- è‹±æ–‡: \"{eng}\"\n"
    "- ä¸­æ–‡: \"{chn}\"\n\n"
    "è¿™ä»½å¥å­çš„ç¬”è®°è‰ç¨¿ï¼ˆä½ éœ€è¦ä¿®æ”¹å’Œç²¾ç‚¼å®ƒï¼‰:\n"
    "--- è‰ç¨¿å¼€å§‹ ---\n"
    "{draft_note}\n"
    "--- è‰ç¨¿ç»“æŸ ---\n\n"
    "ã€å‚è€ƒ1ã€‘æœ¬è¯¾æ‰€æœ‰å†…å®¹çš„è‰ç¨¿ (ä¾›ä½ é€šè§ˆå…¨å±€ï¼Œå¯»æ‰¾è¿œè·ç¦»å…³è”):\n"
    "{full_context}\n\n"
    "ã€å‚è€ƒ2ã€‘æœ¬è¯¾å·²æŒ‰é¡ºåºç²¾ç‚¼è¿‡çš„ç¬”è®° (ä¾›ä½ å›é¡¾è¿‘æœŸå†…å®¹ï¼Œé¿å…é‡å¤):\n"
    "{refined_context}\n"
    "--------------------------------\n"
    "--- å…¨æ–‡èƒŒæ™¯å¼€å§‹ ---\n"
    "{full_context}\n"
    "--- å…¨æ–‡èƒŒæ™¯ç»“æŸ ---\n\n"
    "--- å·²ç²¾ç‚¼ç¬”è®°å¼€å§‹ ---\n"
    "{refined_context}\n"
    "--- å·²ç²¾ç‚¼ç¬”è®°ç»“æŸ ---\n\n"
    "ç°åœ¨ï¼Œè¯·è¾“å‡ºä½ å¯¹ä¸Šé¢é‚£ä»½â€œç¬”è®°è‰ç¨¿â€è¿›è¡Œç²¾ç‚¼å’Œå…³è”åçš„æœ€ç»ˆç‰ˆæœ¬:è¾“å‡ºç¤ºä¾‹ï¼šã€æ ¸å¿ƒè¯æ±‡ã€‘ **have (vt.)**: â€œæ‹¥æœ‰ï¼Œæœ‰â€ã€‚è¿™æ˜¯è‹±è¯­ä¸­æœ€åŸºç¡€çš„åŠ¨è¯ä¹‹ä¸€ï¼Œè¡¨ç¤ºæ‰€å±å…³ç³»ã€‚ ã€å…³è”ç‚¹ã€‘: åœ¨æœ¬è¯¾ä¸­ï¼Œæˆ‘ä»¬è¿˜ä¼šé‡åˆ°è¡¨ç¤ºâ€œå±äºâ€çš„ `belong to`ã€‚`have` å¼ºè°ƒä¸»åŠ¨æ‹¥æœ‰ï¼Œå¦‚ `We have an instrument.` (æˆ‘ä»¬æ‹¥æœ‰ä¸€ä»¶ä¹å™¨)ã€‚è€Œ `It has belonged to our family for a long time.` (å®ƒå±äºæˆ‘ä»¬å®¶å¾ˆä¹…äº†) åˆ™å¼ºè°ƒè¢«åŠ¨åœ°â€œå±äºâ€æŸä¸ªç¾¤ä½“æˆ–ä¸ªäººï¼Œå¹¶æŒç»­äº†ä¸€æ®µæ—¶é—´ã€‚æ³¨æ„å®ƒä»¬åœ¨è¡¨è¾¾â€œæ‰€å±â€æ—¶çš„ä¸åŒä¾§é‡ã€å¥å‹è§£æã€‘ï¼šä¸»è°“å®¾ (S + V + O)    `We` (ä¸»è¯­ S) + `have` (è°“è¯­ V) + `an old musical instrument` (å®¾è¯­ O)ã€‚ è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„â€œä¸»è°“å®¾â€å¥å‹ï¼Œç›´æ¥è¯´æ˜â€œè°æ‹¥æœ‰ä»€ä¹ˆâ€ã€‚`old` å’Œ `musical` æ˜¯å½¢å®¹è¯ï¼Œå®ƒä»¬ä¿®é¥°åè¯ `instrument`ï¼Œå…·ä½“æè¿°äº†ä¹å™¨çš„ç‰¹å¾ã€‚ã€ä¸¾ä¸€åä¸‰ã€‘ï¼šI have a new car. (æˆ‘æœ‰ä¸€è¾†æ–°è½¦ã€‚) She has a big house. (å¥¹æœ‰ä¸€æ ‹å¤§æˆ¿å­ã€‚)\n"
)


def process_lesson_with_gemini(lesson_data):
    flash_model = genai.GenerativeModel(model_name=FLASH_MODEL_NAME, generation_config=GENERATION_CONFIG, safety_settings=safety_settings)
    pro_model = genai.GenerativeModel(model_name=PRO_MODEL_NAME, generation_config=GENERATION_CONFIG, safety_settings=safety_settings)
    
    # ... åˆ†å¥é€»è¾‘ ...
    prompt_split = f"ä½ çš„ä»»åŠ¡æ˜¯å°†ä¸€æ®µè‹±æ–‡å’Œå…¶å¯¹åº”çš„ä¸­æ–‡ç¿»è¯‘ï¼Œä¸€å¥å¯¹ä¸€å¥åœ°ç²¾å‡†é…å¯¹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§â€œè‹±æ–‡å¥å­ | ä¸­æ–‡å¥å­â€çš„æ ¼å¼è¾“å‡º...\n\nè‹±æ–‡è¯¾æ–‡:\n{lesson_data['english']}\n\nä¸­æ–‡è¯‘æ–‡:\n{lesson_data['chinese']}"
    try:
        response = flash_model.generate_content(prompt_split)
        if not response.parts: raise ValueError(f"åˆ†å¥APIå“åº”ä¸ºç©º, åŸå› : {response.candidates[0].finish_reason}")
        sentence_pairs = [(p[0].strip(), p[1].strip()) for line in response.text.strip().split('\n') if '|' in line and len(p := line.split('|', 1)) == 2]
    except Exception as e:
        print(f"   - âŒ è°ƒç”¨Geminiåˆ†å¥å‡ºé”™ï¼Œå·²ä¸­æ­¢: {e}"); return None
    if not sentence_pairs:
        print("   - âš ï¸ æœªèƒ½æˆåŠŸé…å¯¹å¥å­ï¼Œå¤„ç†ä¸­æ–­ã€‚"); return None

    # --- é˜¶æ®µ1: å¹¶è¡Œç”Ÿæˆè‰ç¨¿ ---
    print(f"   - âœ… æ™ºèƒ½åˆ†å¥å®Œæˆï¼Œå…± {len(sentence_pairs)} å¥ã€‚å¼€å§‹å¹¶è¡Œç”Ÿæˆè‰ç¨¿...")
    draft_notes = {}
    def generate_single_draft(sentence_pair):
        eng, chn = sentence_pair
        try:
            draft_prompt_filled = prompt_for_draft.format(eng=eng, chn=chn, vocabulary=lesson_data.get('vocabulary', ''))
            response = flash_model.generate_content(draft_prompt_filled)
            if not response.parts: raise ValueError(f"APIå“åº”ä¸ºç©º, åŸå› : {response.candidates[0].finish_reason}")
            return eng, response.text.strip()
        except Exception as e:
            return eng, "è‰ç¨¿ç”Ÿæˆå¤±è´¥ã€‚"
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_THREAD_WORKERS_FOR_DRAFTS) as executor:
        results = executor.map(generate_single_draft, sentence_pairs)
        for eng, draft_note in results:
            draft_notes[eng] = draft_note

    # --- é˜¶æ®µ2: ä¸²è¡Œç²¾ç‚¼ç¬”è®° (ä½¿ç”¨åŒé‡ä¸Šä¸‹æ–‡) ---
    print("   - âœ… æ‰€æœ‰è‰ç¨¿ç”Ÿæˆå®Œæ¯•ã€‚å¼€å§‹ä½¿ç”¨Proæ¨¡å‹è¿›è¡ŒåŒé‡ä¸Šä¸‹æ–‡ç²¾ç‚¼...")
    final_notes_data = []
    for i, (eng, chn) in enumerate(sentence_pairs):
        final_note = None
        for attempt in range(MAX_RETRIES_PER_SENTENCE):
            try:
                print(f"  - æ­£åœ¨ç²¾ç‚¼ç¬¬ {i+1}/{len(sentence_pairs)} å¥ (Proæ¨¡å‹, å°è¯• {attempt + 1}/{MAX_RETRIES_PER_SENTENCE})...")
                draft_note = draft_notes.get(eng, "")
                
                # <<< æ ¸å¿ƒæ”¹åŠ¨ï¼šåŒæ—¶æ„å»ºä¸¤ç§ä¸Šä¸‹æ–‡ >>>
                # ä¸Šä¸‹æ–‡1: å…¨æ–‡è‰ç¨¿ (ç”¨äºå…¨å±€è§†é‡)
                other_drafts = [f"- {o_eng}\n  è‰ç¨¿: {o_note}" for o_eng, o_note in draft_notes.items() if o_eng != eng]
                full_context = "\n".join(other_drafts)

                # ä¸Šä¸‹æ–‡2: å·²ç²¾ç‚¼ç¬”è®° (ç”¨äºæ»šåŠ¨è®°å¿†)
                if not final_notes_data:
                    refined_context = "ï¼ˆè¿™æ˜¯æœ¬è¯¾ç¬¬ä¸€å¥ï¼Œå°šæ— å·²ç²¾ç‚¼çš„ç¬”è®°ï¼‰"
                else:
                    context_lines = [f"- {item['english']}\n  æœ€ç»ˆç¬”è®°: {item['note']}" for item in final_notes_data]
                    refined_context = "\n".join(context_lines)

                # å°†ä¸¤ç§ä¸Šä¸‹æ–‡éƒ½å¡«å……åˆ°Promptä¸­
                refinement_prompt_filled = prompt_for_refinement.format(
                    eng=eng, chn=chn, draft_note=draft_note, 
                    full_context=full_context, 
                    refined_context=refined_context
                )
                
                response = pro_model.generate_content(refinement_prompt_filled, request_options={"timeout": 300})
                if not response.parts: raise ValueError(f"APIå“åº”ä¸ºç©º, åŸå› : {response.candidates[0].finish_reason}")
                
                final_note = response.text.strip()
                break
            except Exception as e:
                print(f"    - âš ï¸ ç²¾ç‚¼å°è¯•å¤±è´¥: {e}")
                if attempt < MAX_RETRIES_PER_SENTENCE - 1:
                    print("    - æ­£åœ¨ç­‰å¾…5ç§’åé‡è¯•..."); time.sleep(5)
                else:
                    print(f"    - âŒ å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œç²¾ç‚¼å¤±è´¥ã€‚")
        
        if final_note is not None:
            final_notes_data.append({"english": eng, "chinese": chn, "note": final_note})
        else:
            print(f"   - âŒ ç”±äºå¥å­â€œ{eng[:20]}...â€ç²¾ç‚¼å¤±è´¥ï¼Œæœ¬è¯¾({lesson_data['filename']})å¤„ç†ä¸­æ­¢ã€‚")
            return None
        
        time.sleep(1)

    print(f"   - âœ… æ•´ç¯‡è¯¾æ–‡({lesson_data['filename']})æ‰€æœ‰å¥å­ç²¾ç‚¼æˆåŠŸï¼")
    return final_notes_data

# ... process_single_file å’Œ main å‡½æ•°ä¿æŒä¸å˜ ...
def process_single_file(filename):
    if GOOGLE_API_KEY:
        genai.configure(api_key=GOOGLE_API_KEY)
    else:
        return f"âŒ é”™è¯¯ï¼šå­è¿›ç¨‹æ— æ³•æ‰¾åˆ°GOOGLE_API_KEYã€‚"
    raw_filepath = os.path.join(RAW_DATA_DIR, filename)
    processed_filepath = os.path.join(PROCESSED_DATA_DIR, filename)
    if os.path.exists(processed_filepath):
        return f"ğŸŸ¡ {filename} å·²æˆåŠŸå¤„ç†ï¼Œè·³è¿‡ã€‚"
    print(f"ğŸš€ å¼€å§‹å¤„ç†æ–‡ä»¶: {filename}")
    with open(raw_filepath, 'r', encoding='utf-8') as f:
        lesson_data = json.load(f)
    lesson_data['filename'] = filename 
    anki_notes = process_lesson_with_gemini(lesson_data)
    if anki_notes:
        with open(processed_filepath, 'w', encoding='utf-8') as f:
            json.dump(anki_notes, f, ensure_ascii=False, indent=4)
        return f"âœ… æ–‡ä»¶ {filename} å¤„ç†æˆåŠŸï¼Œå·²ä¿å­˜ã€‚"
    else:
        return f"âŒ æ–‡ä»¶ {filename} å¤„ç†å¤±è´¥ï¼Œå°†åœ¨ä¸‹æ¬¡è¿è¡Œæ—¶é‡è¯•ã€‚"

def main():
    print(f"ğŸš€ è„šæœ¬2ï¼šå¹¶è¡Œå¤„ç†å¯åŠ¨ (ä½¿ç”¨ {MAX_PROCESS_WORKERS} ä¸ªè¿›ç¨‹) ğŸš€")
    if not GOOGLE_API_KEY:
        print("âŒ é”™è¯¯ï¼šæœªåœ¨.envæ–‡ä»¶ä¸­æ‰¾åˆ°GOOGLE_API_KEYã€‚"); return
    os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)
    raw_files = sorted([f for f in os.listdir(RAW_DATA_DIR) if f.endswith('.json') and not f.startswith('.')])
    if not raw_files:
        print("ğŸŸ¡ åœ¨raw_dataæ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°è¦å¤„ç†çš„æ–‡ä»¶ã€‚"); return
    with concurrent.futures.ProcessPoolExecutor(max_workers=MAX_PROCESS_WORKERS) as executor:
        results = executor.map(process_single_file, raw_files)
        for result in results:
            print(result)
    print("\nğŸ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæ¯•ï¼è¯·æ£€æŸ¥æ—¥å¿—ä¸­æ˜¯å¦æœ‰å¤„ç†å¤±è´¥çš„æ–‡ä»¶ã€‚")

if __name__ == '__main__':
    main()