# 2_process_with_ai.py
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import json
import os
import time
from dotenv import load_dotenv

# --- é…ç½® ---
load_dotenv() 
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
BOOK_TO_PROCESS = 3
RAW_DATA_DIR = os.path.join("raw_data", f"nce_book_{BOOK_TO_PROCESS}")
PROCESSED_DATA_DIR = os.path.join("processed_data", f"nce_book_{BOOK_TO_PROCESS}")
MODEL_NAME = "gemini-2.5-flash"
GENERATION_CONFIG = {"temperature": 0.4, "top_p": 1, "top_k": 1, "max_output_tokens": 8000}

# ------------
safety_settings = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}

# <<< æ–°å¢ï¼šä¸ºç¬¬ä¸€é˜¶æ®µï¼ˆç”Ÿæˆè‰ç¨¿ï¼‰è®¾è®¡çš„Prompt >>>
prompt_for_draft = (
    "ä½ æ˜¯ä¸€ä½é¡¶çº§çš„è‹±è¯­è€å¸ˆï¼Œä¸“é—¨ä¸ºä¸­æ–‡ä¸ºæ¯è¯­ã€è¯æ±‡é‡åœ¨1000-2000çš„åˆå­¦è€…è®²è§£æ–°æ¦‚å¿µè‹±è¯­ã€‚ä½ çš„è®²è§£å¿…é¡»ç®€æ˜æ‰¼è¦ã€å½¢è±¡ç”ŸåŠ¨ã€å…¨éƒ¨ä½¿ç”¨ä¸­æ–‡ã€‚\n\n"
    "è¾“å‡ºæ ¼å¼è§„åˆ™ï¼š\n"
    "1. åˆ—è¡¨è¯·ç›´æ¥ä½¿ç”¨ â€œ1.â€, â€œ2.â€ è¿™æ ·çš„æ•°å­—å‰ç¼€ã€‚\n\n"
    "1. ç»å¯¹ä¸è¦ä½¿ç”¨ä»»ä½•Markdownæˆ–HTMLæ ‡ç­¾ï¼ˆä¾‹å¦‚ `<b>`, `<br>` ç­‰ï¼‰ã€‚æ‰€æœ‰å†…å®¹éƒ½å¿…é¡»æ˜¯çº¯æ–‡æœ¬ã€‚\n"
    "è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ä¸‰éƒ¨åˆ†å†…å®¹å’Œæ ¼å¼ï¼Œä¸ºæä¾›çš„å¥å­ç”Ÿæˆå­¦ä¹ ç¬”è®°ï¼š\n"
    "è¦ç”¨åˆ°çš„è®²è§£æ¶æ„ï¼š å¥å‹-è¯æ€§ï¼šæ‰€æœ‰çš„ç®€å•å¥åªæœ‰äº”ç§ï¼ˆå³è‹±è¯­çš„äº”ç§å¥å‹ï¼‰â€”â€”ç”±å¥å­ä¸­çš„åŠ¨è¯å†³å®š/ç”±éœ€è¦è¡¨è¾¾çš„æ„æ€å†³å®šã€‚åŠ¨è¯ï¼šè¡¨ç¤ºçŠ¶æ€æˆ–åŠ¨ä½œçš„è¯æ±‡ï¼› ä¸åŠç‰©åŠ¨è¯vi.ï¼ŒåŠç‰©åŠ¨è¯vt.ï¼Œç³»åŠ¨è¯ï¼ˆis, seem, proveï¼Œè¡¨ç¤ºçŠ¶æ€ï¼‰ï¼ŒåŒå®¾è¯­åŠ¨è¯ï¼Œéœ€è¦å®¾è¡¥çš„åŠ¨è¯ç­‰ã€‚S + V (ä¸»è°“)**: The sun rises.S + V + O (ä¸»è°“å®¾)**: I love English.S + V + P (ä¸»è°“è¡¨)**: The story **is** true. (ç³»åŠ¨è¯)S + V + o + O (ä¸»è°“åŒå®¾)**: My mom bought **me** a **book**.S + V + O + C (ä¸»è°“å®¾è¡¥)**: I painted the wall **blue**."
    "1. è¯æ±‡ä¸çŸ­è¯­\n"
    "è§£é‡Šé‡ç‚¹å•è¯æˆ–è¯ç»„çš„å«ä¹‰ã€è¯æ€§(vt./vi./adj./adv.ç­‰)ã€å‘éŸ³éš¾ç‚¹å’Œå®ç”¨æ­é…ã€‚æ³¨æ„ï¼Œ2-5ä¸ªé‡ç‚¹å³å¯ï¼Œå¦åˆ™ä¼šç»™å­¦ä¹ è€…å¸¦æ¥ä¸å¿…è¦çš„æ–‡å­—å’Œè´Ÿæ‹…\n\n"
    "2. å¥å­ç»“æ„åˆ†æ\n"
    "è¿™æ˜¯æœ€é‡è¦çš„éƒ¨åˆ†ï¼ŒæŠŠæ‰€æœ‰çš„ç®€å•å¥éƒ½åˆ†æä¸€ä¸‹ï¼Œè¿‡äºç®€å•çš„å¥å­å¯ä»¥çœç•¥ã€‚è¯·ä¸¥æ ¼å‚è€ƒä»¥ä¸‹ç¤ºä¾‹çš„æ€è·¯å’Œæ ¼å¼è¿›è¡Œåˆ†æï¼š\n"
    "--- ç¤ºä¾‹å¼€å§‹ ---\n"
    "å¥å­: If you park your car in the wrong place, a traffic policeman will soon find it.\n"
    "åˆ†æ:\n"
    "è¿™æ˜¯ä¸€ä¸ªæ¡ä»¶å¥ï¼Œå‘Šè¯‰æˆ‘ä»¬ä¸€ä¸ªåŠ¨ä½œï¼ˆåœè½¦ï¼‰ä¼šå¸¦æ¥ä¸€ä¸ªåæœï¼ˆè¢«å‘ç°ï¼‰ã€‚\n"
    "1. è¿™ä¸ªå¥å­çš„â€œä¸»è§’â€æ˜¯ååŠéƒ¨åˆ† \"a traffic policeman will soon find it\" (è­¦å¯Ÿä¼šå‘ç°å®ƒ)ï¼Œè¿™æ˜¯ä¸€ä¸ªâ€œä¸»è°“å®¾â€å¥å‹ï¼Œæ¸…æ¥šåœ°è¯´æ˜äº†è­¦å¯Ÿä¼šåšä»€ä¹ˆäº‹ã€‚\n"
    "2. å‰åŠéƒ¨åˆ† \"If you park your car...\" (å¦‚æœä½ æŠŠè½¦åœåœ¨é”™è¯¯çš„åœ°æ–¹) æ˜¯ä¸€ä¸ªæ¡ä»¶ï¼Œåƒä¸ªâ€œå¦‚æœ...å°±...â€çš„å¼€å…³ï¼Œå‘Šè¯‰æˆ‘ä»¬â€œä¸»è§’â€äº‹ä»¶åœ¨ä»€ä¹ˆæƒ…å†µä¸‹ä¼šå‘ç”Ÿã€‚\n"
    "3. æ—¶æ€ï¼šä¸»å¥ç”¨äº†å°†æ¥æ—¶ (will find)ï¼Œè¡¨ç¤ºå¯¹æœªæ¥çš„é¢„æµ‹ï¼›æ¡ä»¶éƒ¨åˆ†ç”¨äº†ç°åœ¨æ—¶ (park) ä»£æ›¿å°†æ¥æ—¶ï¼Œè¿™æ˜¯ifæ¡ä»¶å¥çš„å›ºå®šè§„åˆ™ã€‚\n"
    "--- ç¤ºä¾‹ç»“æŸ ---\n"
    "3. ä¸¾ä¸€åä¸‰\n"
    "è¯·æä¾›1-2ä¸ªä¸åŸå¥æ ¸å¿ƒè¯æ±‡æˆ–å¥å‹ç›¸ä¼¼çš„ã€ç®€å•çš„ä¾‹å¥ï¼Œå¹¶é™„ä¸Šä¸­æ–‡ç¿»è¯‘ã€‚\n"
    "------------------------------------------------------------------\n\n"
    "æœ¬è¯¾ç”Ÿè¯å‚è€ƒ: {vocabulary}\n"
    "éœ€è¦åˆ†æçš„å¥å­:\n"
    "- è‹±æ–‡: \"{eng}\"\n"
    "- ä¸­æ–‡: \"{chn}\"\n\n"
)

# <<< æ–°å¢ï¼šä¸ºç¬¬äºŒé˜¶æ®µï¼ˆç²¾ç‚¼ç¬”è®°ï¼‰è®¾è®¡çš„Prompt >>>
prompt_for_refinement = (
    "ä½ æ˜¯ä¸€ä½é¡¶çº§çš„è‹±è¯­æ•™å­¦ç¼–è¾‘ï¼Œä½ çš„ä»»åŠ¡æ˜¯â€œç²¾ç‚¼å¹¶å…³è”â€ä¸€ä»½ç¬”è®°è‰ç¨¿ã€‚\n\n"
    "æ ¸å¿ƒåŸåˆ™ï¼š\n"
    "1. **ç²¾ç‚¼ç®€æ´**: ä¸¥æ ¼éµå®ˆâ€œå°‘å³æ˜¯å¤šâ€ï¼Œåˆ é™¤è‰ç¨¿ä¸­æ‰€æœ‰éå¿…è¦çš„ã€é‡å¤çš„æˆ–è¿‡äºåŸºç¡€çš„ä¿¡æ¯ã€‚æœ€ç»ˆç¬”è®°è¦ç®€æ˜æ‰¼è¦ï¼Œä¸è¦ç»™åˆå­¦è€…é€ æˆè´Ÿæ‹…ã€‚\n"
    "2. **æ·±åº¦å…³è”**: è¿™æ˜¯ä½ çš„æ ¸å¿ƒä»·å€¼ã€‚è¯·ä»”ç»†é˜…è¯»ä¸‹é¢æä¾›çš„â€œæœ¬è¯¾æ‰€æœ‰å…¶ä»–å¥å­çš„ç¬”è®°è‰ç¨¿â€ï¼Œå¦‚æœå½“å‰å¥å­çš„çŸ¥è¯†ç‚¹ï¼ˆè¯æ±‡/å¥å‹ï¼‰ä¸å®ƒä»¬æœ‰å…³è”ï¼Œè¯·ç”¨â€œè¿™å’Œæˆ‘ä»¬ä¹‹å‰é‡åˆ°çš„...ç±»ä¼¼â€æˆ–â€œæ³¨æ„åŒºåˆ†...â€ç­‰æ–¹å¼ç‚¹æ˜ï¼Œå¸®åŠ©å­¦ç”Ÿå»ºç«‹è”ç³»ã€‚\n"
    "3. **ä¼˜åŒ–è¡¨è¾¾**: ç”¨æ›´ç”ŸåŠ¨ã€æ›´æ˜“äºç†è§£çš„æ–¹å¼é‡å†™è‰ç¨¿ï¼Œç¡®ä¿æœ€ç»ˆç‰ˆæœ¬æ¸…æ™°ã€æµç•…ã€‚\n\n"
    "è¾“å‡ºæ ¼å¼ï¼šçº¯æ–‡æœ¬ï¼Œç”¨æ•°å­—å‰ç¼€åˆ†ç‚¹ã€‚ç»å¯¹ä¸è¦ä½¿ç”¨markdownæ ¼å¼ï¼ï¼ï¼ï¼ï¼ä¹Ÿä¸è¦ä½¿ç”¨\nçš„æ ¼å¼ï¼ï¼ï¼ï¼ï¼æ³¨æ„ç²¾ç‚¼ä¹‹åæ¯ä¸€ä¸ªå¥å­å¡ç‰‡çš„è§£æçš„å­—æ•°ä¸èƒ½è¶…è¿‡100å­—ï¼ï¼ï¼ï¼å…³è”å¼€å§‹çš„æ—¶å€™åªéœ€è¦æ ‡æ³¨ã€å…³è”ç‚¹ã€‘å³å¯\n"
    "------------------------------------------------------------------\n"
    "å½“å‰è¦ç²¾ç‚¼çš„å¥å­:\n"
    "- è‹±æ–‡: \"{eng}\"\n"
    "- ä¸­æ–‡: \"{chn}\"\n\n"
    "è¿™ä»½å¥å­çš„ç¬”è®°è‰ç¨¿ï¼ˆä½ éœ€è¦ä¿®æ”¹å’Œç²¾ç‚¼å®ƒï¼‰:\n"
    "--- è‰ç¨¿å¼€å§‹ ---\n"
    "{draft_note}\n"
    "--- è‰ç¨¿ç»“æŸ ---\n\n"
    "ã€é‡è¦å‚è€ƒã€‘æœ¬è¯¾æ‰€æœ‰å…¶ä»–å¥å­çš„ç¬”è®°è‰ç¨¿ï¼ˆä¾›ä½ å¯»æ‰¾å…³è”ç‚¹ï¼‰:\n"
    "--- å…¨æ–‡èƒŒæ™¯å¼€å§‹ ---\n"
    "{full_context}\n"
    "--- å…¨æ–‡èƒŒæ™¯ç»“æŸ ---\n\n"
    "ç°åœ¨ï¼Œè¯·è¾“å‡ºä½ å¯¹ä¸Šé¢é‚£ä»½â€œç¬”è®°è‰ç¨¿â€è¿›è¡Œç²¾ç‚¼å’Œå…³è”åçš„æœ€ç»ˆç‰ˆæœ¬:è¾“å‡ºç¤ºä¾‹ï¼šã€æ ¸å¿ƒè¯æ±‡ã€‘ **have (vt.)**: â€œæ‹¥æœ‰ï¼Œæœ‰â€ã€‚è¿™æ˜¯è‹±è¯­ä¸­æœ€åŸºç¡€çš„åŠ¨è¯ä¹‹ä¸€ï¼Œè¡¨ç¤ºæ‰€å±å…³ç³»ã€‚ ã€å…³è”ç‚¹ã€‘: åœ¨æœ¬è¯¾ä¸­ï¼Œæˆ‘ä»¬è¿˜ä¼šé‡åˆ°è¡¨ç¤ºâ€œå±äºâ€çš„ `belong to`ã€‚`have` å¼ºè°ƒä¸»åŠ¨æ‹¥æœ‰ï¼Œå¦‚ `We have an instrument.` (æˆ‘ä»¬æ‹¥æœ‰ä¸€ä»¶ä¹å™¨)ã€‚è€Œ `It has belonged to our family for a long time.` (å®ƒå±äºæˆ‘ä»¬å®¶å¾ˆä¹…äº†) åˆ™å¼ºè°ƒè¢«åŠ¨åœ°â€œå±äºâ€æŸä¸ªç¾¤ä½“æˆ–ä¸ªäººï¼Œå¹¶æŒç»­äº†ä¸€æ®µæ—¶é—´ã€‚æ³¨æ„å®ƒä»¬åœ¨è¡¨è¾¾â€œæ‰€å±â€æ—¶çš„ä¸åŒä¾§é‡ã€å¥å‹è§£æã€‘ï¼šä¸»è°“å®¾ (S + V + O)    `We` (ä¸»è¯­ S) + `have` (è°“è¯­ V) + `an old musical instrument` (å®¾è¯­ O)ã€‚ è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„â€œä¸»è°“å®¾â€å¥å‹ï¼Œç›´æ¥è¯´æ˜â€œè°æ‹¥æœ‰ä»€ä¹ˆâ€ã€‚`old` å’Œ `musical` æ˜¯å½¢å®¹è¯ï¼Œå®ƒä»¬ä¿®é¥°åè¯ `instrument`ï¼Œå…·ä½“æè¿°äº†ä¹å™¨çš„ç‰¹å¾ã€‚ã€ä¸¾ä¸€åä¸‰ã€‘ï¼šI have a new car. (æˆ‘æœ‰ä¸€è¾†æ–°è½¦ã€‚) She has a big house. (å¥¹æœ‰ä¸€æ ‹å¤§æˆ¿å­ã€‚)\n"
)


def process_lesson_with_gemini(lesson_data):
    model = genai.GenerativeModel(model_name=MODEL_NAME, generation_config=GENERATION_CONFIG, safety_settings=safety_settings)
    prompt_split = f"ä½ çš„ä»»åŠ¡æ˜¯å°†ä¸€æ®µè‹±æ–‡å’Œå…¶å¯¹åº”çš„ä¸­æ–‡ç¿»è¯‘ï¼Œä¸€å¥å¯¹ä¸€å¥åœ°ç²¾å‡†é…å¯¹ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§â€œè‹±æ–‡å¥å­ | ä¸­æ–‡å¥å­â€çš„æ ¼å¼è¾“å‡º...\n\nç°åœ¨è¯·å¤„ç†ä»¥ä¸‹å†…å®¹ï¼š\nè‹±æ–‡è¯¾æ–‡:\n{lesson_data['english']}\n\nä¸­æ–‡è¯‘æ–‡:\n{lesson_data['chinese']}"
    try:
        response = model.generate_content(prompt_split)
        sentence_pairs = []
        for line in response.text.strip().split('\n'):
            if '|' in line:
                parts = line.split('|', 1)
                if len(parts) == 2:
                    sentence_pairs.append((parts[0].strip(), parts[1].strip()))
        print(f"   - âœ… æ™ºèƒ½åˆ†å¥å®Œæˆï¼Œå…± {len(sentence_pairs)} å¥ã€‚")
    except Exception as e:
        print(f"\n   - âŒ è°ƒç”¨Geminiåˆ†å¥æ—¶å‡ºé”™: {e}"); return None
    if not sentence_pairs:
        print("   - âš ï¸ æœªèƒ½æˆåŠŸé…å¯¹å¥å­ï¼Œå¤„ç†ä¸­æ–­ã€‚"); return None

    # --- é˜¶æ®µ1: ç”Ÿæˆæ‰€æœ‰å¥å­çš„ç¬”è®°è‰ç¨¿ ---
    print("\n--- [é˜¶æ®µ1: æ­£åœ¨ç”Ÿæˆè‰ç¨¿ç¬”è®°ï¼Œæ­¤é˜¶æ®µæˆæœ¬è¾ƒä½] ---")
    draft_notes = {}
    for i, (eng, chn) in enumerate(sentence_pairs):
        print(f"  - æ­£åœ¨ä¸ºç¬¬ {i+1}/{len(sentence_pairs)} å¥ç”Ÿæˆè‰ç¨¿...")
        try:
            # <<< ä¿®æ­£ï¼šåœ¨è¿™é‡Œä½¿ç”¨.format()æ–¹æ³•ï¼Œå¹¶æä¾›æ‰€æœ‰éœ€è¦çš„å˜é‡ >>>
            draft_prompt_filled = prompt_for_draft.format(
                eng=eng, 
                chn=chn, 
                vocabulary=lesson_data.get('vocabulary', '') # ä½¿ç”¨.getä»¥é˜²ä¸‡ä¸€æ²¡æœ‰'vocabulary'é”®
            )
            response = model.generate_content(draft_prompt_filled)
            draft_notes[eng] = response.text.strip()
        except Exception as e:
            print(f"  - âŒ ç”Ÿæˆè‰ç¨¿å¤±è´¥: {e}")
            draft_notes[eng] = "è‰ç¨¿ç”Ÿæˆå¤±è´¥ã€‚"
        time.sleep(1)
    print("--- [é˜¶æ®µ1: æ‰€æœ‰è‰ç¨¿ç”Ÿæˆå®Œæ¯•] ---")

    # --- é˜¶æ®µ2: ç²¾ç‚¼å¹¶å…³è”ç¬”è®° ---
    print("\n--- [é˜¶æ®µ2: æ­£åœ¨ç²¾ç‚¼å¹¶å…³è”ç¬”è®°ï¼Œæ­¤é˜¶æ®µæ›´æ™ºèƒ½] ---")
    final_notes_data = []
    for i, (eng, chn) in enumerate(sentence_pairs):
        print(f"  - æ­£åœ¨ç²¾ç‚¼ç¬¬ {i+1}/{len(sentence_pairs)} å¥çš„ç¬”è®°...")
        
        draft_note_for_current_sentence = draft_notes.get(eng, "")
        
        # æ„å»ºç”¨äºå‚è€ƒçš„â€œå…¨æ–‡èƒŒæ™¯â€
        other_drafts = []
        for other_eng, other_note in draft_notes.items():
            if other_eng != eng:
                other_drafts.append(f"å¥å­: {other_eng}\nç¬”è®°è‰ç¨¿: {other_note}\n")
        full_context = "\n".join(other_drafts)

        # å¡«å……æœ€ç»ˆçš„ç²¾ç‚¼Prompt
        refinement_prompt_filled = prompt_for_refinement.format(
            eng=eng,
            chn=chn,
            draft_note=draft_note_for_current_sentence,
            full_context=full_context
        )
        
        try:
            response = model.generate_content(refinement_prompt_filled, request_options={"timeout": 180})
            final_note = response.text.strip()
            final_notes_data.append({"english": eng, "chinese": chn, "note": final_note})
        except Exception as e:
            print(f"  - âŒ ç²¾ç‚¼ç¬”è®°å¤±è´¥: {e}")
            # å³ä½¿ç²¾ç‚¼å¤±è´¥ï¼Œä¹Ÿä¿ç•™è‰ç¨¿ä½œä¸ºå¤‡ç”¨
            final_notes_data.append({"english": eng, "chinese": chn, "note": f"ç²¾ç‚¼å¤±è´¥ï¼Œä¿ç•™è‰ç¨¿ï¼š\n{draft_note_for_current_sentence}"})
        time.sleep(1)
    print("--- [é˜¶æ®µ2: æ‰€æœ‰ç¬”è®°ç²¾ç‚¼å®Œæ¯•] ---")
    
    print("\nâœ… æ•´ç¯‡è¯¾æ–‡å¤„ç†å®Œæˆã€‚")
    return final_notes_data


def main():
    print("ğŸš€ è„šæœ¬2ï¼šä½¿ç”¨Gemini APIå¤„ç†åŸå§‹æ•°æ® ğŸš€")
    if "YOUR_NEW_GOOGLE_API_KEY" in GOOGLE_API_KEY:
        print("âŒ é”™è¯¯ï¼šè¯·åœ¨è„šæœ¬ä¸­å¡«å…¥æ‚¨æ–°ç”Ÿæˆçš„Google APIå¯†é’¥ï¼")
        return
    try:
        genai.configure(api_key=GOOGLE_API_KEY)
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–Geminiå¤±è´¥: {e}"); return
    os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)
    raw_files = sorted([f for f in os.listdir(RAW_DATA_DIR) if f.endswith('.json')])
    for filename in raw_files:
        raw_filepath = os.path.join(RAW_DATA_DIR, filename)
        processed_filepath = os.path.join(PROCESSED_DATA_DIR, filename)
        if os.path.exists(processed_filepath):
            print(f"ğŸŸ¡ {filename} å·²å¤„ç†è¿‡ï¼Œè·³è¿‡ã€‚")
            continue
        print("\n" + "="*50)
        print(f"ğŸ“„ æ­£åœ¨å¤„ç†æ–‡ä»¶: {filename}")
        with open(raw_filepath, 'r', encoding='utf-8') as f:
            lesson_data = json.load(f)
        if not lesson_data.get('english') or not lesson_data.get('chinese'):
            print("   - âŒ æ–‡ä»¶å†…å®¹ä¸å®Œæ•´ï¼Œè·³è¿‡ã€‚"); continue
        anki_notes = process_lesson_with_gemini(lesson_data)
        if anki_notes:
            with open(processed_filepath, 'w', encoding='utf-8') as f:
                json.dump(anki_notes, f, ensure_ascii=False, indent=4)
            print(f"ğŸ’¾ å·²å°†å¤„ç†ç»“æœä¿å­˜åˆ°: {processed_filepath}")
    print("\nğŸ æ‰€æœ‰åŸå§‹æ•°æ®å¤„ç†å®Œæ¯•ï¼")


if __name__ == '__main__':
    main()