# 1_scrape_lessons.py

import requests
from bs4 import BeautifulSoup
import json
import os
import time

# --- é…ç½® ---
BOOK_TO_SCRAPE = 2
TOTAL_LESSONS = 96
BASE_URL = "http://www.newconceptenglish.com/index.php"
OUTPUT_DIR = os.path.join("raw_data", f"nce_book_{BOOK_TO_SCRAPE}")
MAX_ATTEMPTS = 3 # æ¯ç¯‡è¯¾æ–‡æœ€å¤šå°è¯•æ¬¡æ•°
# ------------

def scrape_nce_lesson(lesson_url):
    """
    æ ¸å¿ƒçˆ¬è™«å‡½æ•°ï¼šä»…è´Ÿè´£ä»URLè·å–å†…å®¹ï¼Œä¸åŒ…å«æ‰“å°é€»è¾‘ã€‚
    è¿”å›ä¸€ä¸ªåŒ…å«å†…å®¹çš„å­—å…¸ï¼Œæˆ–åœ¨å¤±è´¥æ—¶è¿”å›Noneã€‚
    """
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(lesson_url, headers=headers, timeout=20)
        response.raise_for_status()
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')
        
        content = {'english': '', 'chinese': '', 'vocabulary': ''}
        h3_english = soup.find('h3', string='æ–°æ¦‚å¿µè‹±è¯­ï¼è¯¾æ–‡')
        if h3_english and h3_english.find_next_sibling('p'):
            content['english'] = h3_english.find_next_sibling('p').get_text(strip=True)

        h3_chinese = soup.find('h3', string='æ–°æ¦‚å¿µè‹±è¯­ï¼ç¿»è¯‘')
        if h3_chinese and h3_chinese.find_next_sibling('p'):
            content['chinese'] = h3_chinese.find_next_sibling('p').get_text(strip=True)
            
        h3_vocab = soup.find('h3', string='æ–°æ¦‚å¿µè‹±è¯­ï¼å•è¯å’ŒçŸ­è¯­')
        if h3_vocab:
            vocab_parts = []
            for sibling in h3_vocab.next_siblings:
                if sibling.name == 'h3': break
                if isinstance(sibling, str):
                    cleaned_text = sibling.strip()
                    if cleaned_text: vocab_parts.append(cleaned_text)
            content['vocabulary'] = '\n'.join(vocab_parts)
        
        # åªè¦æ ¸å¿ƒå†…å®¹ä¸ä¸ºç©ºï¼Œå°±è®¤ä¸ºæœ¬æ¬¡çˆ¬å–æ˜¯åˆæ­¥æˆåŠŸçš„
        if content['english'] and content['chinese']:
            return content
        else:
            return None
    except Exception:
        # éšè—å…·ä½“é”™è¯¯ï¼Œè®©è°ƒç”¨è€…å¤„ç†é‡è¯•
        return None

def process_single_lesson(lesson_num, book_num):
    """
    å¤„ç†å•ç¯‡è¯¾æ–‡çš„å®Œæ•´æµç¨‹ï¼šçˆ¬å– -> åœ¨çº¿æ ¡éªŒ -> å¤±è´¥é‡è¯• -> ä¿å­˜ã€‚
    è¿™æ˜¯è„šæœ¬çš„æ ¸å¿ƒâ€œè‡ªä¿®æ­£â€é€»è¾‘ã€‚
    """
    output_filepath = os.path.join(OUTPUT_DIR, f"lesson_{lesson_num:03d}.json")
    if os.path.exists(output_filepath):
        print(f"âœ… lesson_{lesson_num:03d}.json å·²å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
        return True

    lesson_url = f"{BASE_URL}?id=course-{book_num}-{lesson_num:03d}"
    print(f"\n--- æ­£åœ¨å¤„ç† Lesson {lesson_num} ---")

    for attempt in range(1, MAX_ATTEMPTS + 1):
        print(f"  - ç¬¬ {attempt}/{MAX_ATTEMPTS} æ¬¡å°è¯•...")
        
        # 1. é¦–æ¬¡çˆ¬å–
        print("    - æ­£åœ¨çˆ¬å–ä¸»è¦æ•°æ®...")
        main_data = scrape_nce_lesson(lesson_url)
        if not main_data:
            print("    - âŒ çˆ¬å–å¤±è´¥ï¼Œç¨åé‡è¯•...")
            time.sleep(2) # ç­‰å¾…2ç§’å†é‡è¯•
            continue

        # 2. åœ¨çº¿æ ¡éªŒ (é€šè¿‡å†æ¬¡çˆ¬å–è¿›è¡Œæ¯”å¯¹)
        print("    - æ­£åœ¨çˆ¬å–æ ¡éªŒæ•°æ®ä»¥è¿›è¡Œæ¯”å¯¹...")
        time.sleep(1) # å‹å¥½è®¿é—®
        verify_data = scrape_nce_lesson(lesson_url)
        if not verify_data:
            print("    - âŒ æ— æ³•è·å–æ ¡éªŒæ•°æ®ï¼Œé‡è¯•...")
            time.sleep(2)
            continue
            
        # 3. å†…å®¹æ¯”å¯¹
        if (main_data['english'] == verify_data['english'] and
            main_data['chinese'] == verify_data['chinese'] and
            main_data['vocabulary'] == verify_data['vocabulary']):
            
            print("    - âœ… æ•°æ®ä¸€è‡´æ€§æ ¡éªŒé€šè¿‡ï¼å†…å®¹å®Œæ•´ã€‚")
            try:
                with open(output_filepath, 'w', encoding='utf-8') as f:
                    json.dump(main_data, f, ensure_ascii=False, indent=4)
                print(f"    - ğŸ’¾ å·²æˆåŠŸä¿å­˜åˆ°: {output_filepath}")
                return True # æˆåŠŸå¤„ç†ï¼Œè¿”å›True
            except IOError as e:
                print(f"    - âŒ æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")
                return False # ä¿å­˜å¤±è´¥ï¼Œä¹Ÿç®—å¤±è´¥

        else:
            print("    - âŒ æ•°æ®ä¸ä¸€è‡´ï¼Œå¯èƒ½å­˜åœ¨ç½‘ç»œä¸ç¨³å®šæ€§ã€‚æ­£åœ¨é‡è¯•...")
            time.sleep(2)

    # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†
    print(f"  - âŒ Lesson {lesson_num} åœ¨ {MAX_ATTEMPTS} æ¬¡å°è¯•åä»æ— æ³•ç¨³å®šæŠ“å–ï¼Œå·²è·³è¿‡ã€‚")
    return False # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†ï¼Œè¿”å›False

def main():
    """ä¸»æ‰§è¡Œå‡½æ•°ï¼Œè´Ÿè´£è°ƒåº¦æ•´ä¸ªçˆ¬å–æµç¨‹"""
    print("ğŸš€ è„šæœ¬1ï¼šæ–°æ¦‚å¿µè‹±è¯­è‡ªæˆ‘ä¿®æ­£çˆ¬è™« ğŸš€")
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    failed_lessons = []
    for lesson_num in range(1, TOTAL_LESSONS + 1):
        success = process_single_lesson(lesson_num, BOOK_TO_SCRAPE)
        if not success:
            failed_lessons.append(lesson_num)
    
    # --- æœ€ç»ˆæŠ¥å‘Š ---
    print("\n" + "#"*50)
    print("ğŸ“Š æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆã€‚æœ€ç»ˆæŠ¥å‘Šï¼š")
    if not failed_lessons:
        print("âœ…ğŸ‰ğŸ‰ å®Œç¾ï¼æ‰€æœ‰ {TOTAL_LESSONS} ç¯‡è¯¾æ–‡éƒ½å·²æˆåŠŸæŠ“å–å¹¶é€šè¿‡æ ¡éªŒï¼")
    else:
        print(f"âŒ æ³¨æ„ï¼šæœ‰ {len(failed_lessons)} ç¯‡è¯¾æ–‡åœ¨å¤šæ¬¡å°è¯•åä¾ç„¶å¤±è´¥ã€‚")
        print(f"å¤±è´¥çš„è¯¾æ–‡ç¼–å·: {failed_lessons}")
        print("å»ºè®®æ‚¨æ£€æŸ¥ç½‘ç»œæˆ–ç¨åé‡æ–°è¿è¡Œè„šæœ¬ï¼Œç¨‹åºä¼šè‡ªåŠ¨å°è¯•è¿™äº›å¤±è´¥çš„è¯¾æ–‡ã€‚")
    print("#"*50 + "\n")


if __name__ == '__main__':
    main()